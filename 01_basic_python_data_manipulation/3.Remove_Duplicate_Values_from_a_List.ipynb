{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1652f871",
   "metadata": {},
   "source": [
    "# Problem 3: Remove Duplicate Values from a List While Preserving Order\n",
    "\n",
    "---\n",
    "\n",
    "## 1. About the Problem\n",
    "\n",
    "This problem asks me to remove duplicate values from a list while keeping the original order of elements.  \n",
    "In data science, duplicate data can negatively affect analysis and models, so it is important to clean the data before using it.  \n",
    "To solve this problem, I will iterate through the list and keep track of elements I have already seen.  \n",
    "If an element appears again, I will skip it; otherwise, I will store it in a new list.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a999088",
   "metadata": {},
   "source": [
    "## 2. Solution Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c60f314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List after removing duplicates: [10, 20, 30, 40, 50]\n"
     ]
    }
   ],
   "source": [
    "def remove_duplicates(lst):\n",
    "    unique_elements = []\n",
    "    seen = set()\n",
    "    \n",
    "    for item in lst:\n",
    "        if item not in seen:\n",
    "            unique_elements.append(item)\n",
    "            seen.add(item)\n",
    "    \n",
    "    return unique_elements\n",
    "    \n",
    "data = [10, 20, 10, 30, 20, 40, 50, 30]\n",
    "print(\"List after removing duplicates:\", remove_duplicates(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecd2e6c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Summary / Takeaways\n",
    "\n",
    "By solving this problem, I learned how to remove duplicate values efficiently while maintaining the original order of data.  \n",
    "I practiced using sets for fast lookups and lists for preserving sequence.  \n",
    "This type of data cleaning is very common in real-world datasets, especially before performing analysis or building machine learning models.  \n",
    "Understanding how to manage duplicates helps improve data quality and model reliability.  \n",
    "Next, I want to explore how to handle duplicates in large datasets using libraries like Pandas.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
