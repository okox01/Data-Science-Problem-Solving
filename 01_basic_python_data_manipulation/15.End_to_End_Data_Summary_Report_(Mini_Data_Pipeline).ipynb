{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a49fed2",
   "metadata": {},
   "source": [
    "# Problem 15: End-to-End Data Summary Report (Mini Data Pipeline)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. About the Problem\n",
    "\n",
    "This problem asks me to analyze a small numerical dataset and generate a complete summary report.  \n",
    "I will clean the data, compute basic statistics, scale the values, and extract meaningful insights.  \n",
    "This mirrors a real-world data science workflow where raw data is processed step by step before modeling.  \n",
    "The goal is to demonstrate that I understand the full pipeline, not just individual functions.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7160206f",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Solution Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f6f0348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Data:  [45, 50, 60, 70, 80, 90]\n",
      "mean:  65.83\n",
      "median:  65.0\n",
      "Min value:  45\n",
      "Max value:  90\n",
      "Normalized_Data:  [0.0, 0.111, 0.333, 0.556, 0.778, 1.0]\n"
     ]
    }
   ],
   "source": [
    "def clean_data(raw_data):\n",
    "    cleaned=[]\n",
    "    for value in raw_data:\n",
    "        if value!=None and value>=0:\n",
    "            cleaned.append(value)\n",
    "    return cleaned\n",
    "def statistical_operation(data):\n",
    "    total=0\n",
    "    count=0\n",
    "    for value in data:\n",
    "        total+=value\n",
    "        count+=1\n",
    "    mean=total/count\n",
    "\n",
    "    sorted_data=sorted(data)\n",
    "    mid=len(sorted_data)//2\n",
    "    if len(sorted_data)%2==0:\n",
    "        median=(sorted_data[mid-1]+sorted_data[mid])/2\n",
    "    else:\n",
    "        median=sorted_data[mid]\n",
    "    \n",
    "    min_v=data[0]\n",
    "    max_v=data[0]\n",
    "\n",
    "    for value in data:\n",
    "        if value<min_v:\n",
    "            min_v=value\n",
    "    for val in data:\n",
    "        if val>max_v:\n",
    "            max_v=val\n",
    "    \n",
    "    return round(mean,2),median,min_v,max_v\n",
    "def normalizes(data,mi,ma):\n",
    "    normalized_data=[]\n",
    "    for value in data:\n",
    "        norm=round((value-mi)/(ma-mi),3)\n",
    "        normalized_data.append(norm)\n",
    "    return normalized_data\n",
    "\n",
    "# Dataset with missing and invalid values\n",
    "raw_data = [45, 50, None, 60, -10, 70, 80, None, 90]\n",
    "cleaned_datas=clean_data(raw_data)\n",
    "print(\"Cleaned Data: \",cleaned_datas)\n",
    "mean,median,min_val,max_val=statistical_operation(cleaned_datas)\n",
    "print(\"mean: \",mean)\n",
    "print(\"median: \",median)\n",
    "print(\"Min value: \",min_val)\n",
    "print(\"Max value: \",max_val)\n",
    "print(\"Normalized_Data: \",normalizes(cleaned_datas,min_val,max_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c7a9cb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Summary / Takeaways\n",
    "\n",
    "By solving this problem, I practiced handling real-world imperfect data.  \n",
    "I understood how cleaning, analysis, and normalization fit into a single workflow.  \n",
    "This problem helped me think like a data scientist rather than just a programmer.  \n",
    "I learned how each preprocessing step prepares data for machine learning models.  \n",
    "This mini pipeline is something I can confidently showcase in my GitHub portfolio.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
