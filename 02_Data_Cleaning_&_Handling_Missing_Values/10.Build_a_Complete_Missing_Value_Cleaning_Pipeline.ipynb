{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "928a9975",
   "metadata": {},
   "source": [
    "# Topic 02 - Problem 10: Build a Complete Missing-Value Cleaning Pipeline\n",
    "\n",
    "---\n",
    "\n",
    "## 1. About the Problem\n",
    "\n",
    "This problem asks me to build a complete pipeline to handle missing values in a dataset.  \n",
    "Instead of solving one small task, I will combine detection, column removal, and value imputation into one process.  \n",
    "This mimics how data cleaning is done in real data science and machine learning workflows.  \n",
    "To solve this, I will remove columns with too many missing values and fill the remaining missing values using default strategies.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d00505",
   "metadata": {},
   "source": [
    "## 2. Solution Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3345480b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully cleaned dataset: [{'Name': 'Anna'}, {'Name': 'Charlie'}, {'Name': 'Jacob'}, {'Name': 'Unknown'}]\n"
     ]
    }
   ],
   "source": [
    "def clean_missing_data_pipeline(data,threshold_percent,default_values):\n",
    "    missing_counts={}\n",
    "    total=len(data)\n",
    "    for record in data:\n",
    "        for key,value in record.items():\n",
    "            if value is None:\n",
    "                missing_counts[key]=missing_counts.get(key,0)+1\n",
    "    \n",
    "    drop_columns=set()\n",
    "    for cols,count in missing_counts.items():\n",
    "        missing_percent=(count/total)*100\n",
    "        if missing_percent>=threshold_percent:\n",
    "            drop_columns.add(cols)\n",
    "        \n",
    "    cleaned_records=[]\n",
    "    for record in data:\n",
    "        cleaned_dataset={}\n",
    "        for key,value in record.items():\n",
    "            if key not in drop_columns:\n",
    "                if value is None:\n",
    "                    cleaned_dataset[key]=default_values.get(key)\n",
    "                else:\n",
    "                    cleaned_dataset[key]=value\n",
    "        cleaned_records.append(cleaned_dataset)\n",
    "    \n",
    "    return cleaned_records\n",
    "data = [\n",
    "    {\"age\": 25, \"salary\": None, \"city\": \"Dhaka\",'Name':'Anna'},\n",
    "    {\"age\": None, \"salary\": None, \"city\": None,'Name':'Charlie'},\n",
    "    {\"age\": 30, \"salary\": None, \"city\": \"Chittagong\",'Name':'Jacob'},\n",
    "    {\"age\": None, \"salary\": None, \"city\": None,'Name':None}\n",
    "]\n",
    "\n",
    "defaults = {\"age\": 0, \"city\": \"Unknown\",\"Name\":\"Unknown\"}\n",
    "\n",
    "print(\"Fully cleaned dataset:\",\n",
    "      clean_missing_data_pipeline(data, threshold_percent=50, default_values=defaults))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d67092",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Summary / Takeaways\n",
    "\n",
    "By solving this problem, I learned how to design a complete data-cleaning workflow.  \n",
    "I understood how multiple cleaning decisions work together.  \n",
    "This pipeline approach is closer to real-world preprocessing than isolated functions.  \n",
    "Building such logic improves my confidence in handling messy datasets.  \n",
    "Now Iâ€™m ready to move on to exploratory data analysis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
